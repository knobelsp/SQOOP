{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "\n",
    "Dimensions specified below\n",
    "\n",
    "$\\textit{m}$: length of the measurement vector\n",
    "\n",
    "$\\textit{n}$: length of the state (parameter) vector\n",
    "\n",
    "$\\textit{r}$: length of the model error vector\n",
    "\n",
    "\n",
    "To perform this ICA, you'll need a few things:\n",
    "\n",
    "1. Jacobian matrix, defined as the $ K_{j,i}(\\textbf{x}) = \\frac{\\partial F_i (\\textbf{x})}{\\partial x_j}$ where $\\textit{i}$ has length $\\textit{m}$ and $\\textit{j}$ has length $\\textit{n}$. $F(\\textbf{x})$ is the forward model at the state defined by $\\textbf{x}$.\n",
    "\n",
    "    jac [n x m]\n",
    "    \n",
    "2. Model error Jacobian matrix, defined as the $ K_{b,u,i}(\\textbf{x}) = \\frac{\\partial F_i (\\textbf{x})}{\\partial b_u}$ where $\\textit{i}$ has length $\\textit{m}$ and $\\textit{u}$ has length $\\textit{r}$. $F(\\textbf{x})$ is the forward model at the state defined by $\\textbf{x}$. Note there are options in the Rodgers function to omit consideration of model errors if these are not known.\n",
    "\n",
    "    jac_me [r x m]\n",
    "    \n",
    "3. Measurement error coveriance matrix, $S_{\\epsilon}$. This can be specificed as either an $\\textit{m}$ length vector of sigma squared measurement uncertainties or an $\\textit{m} x \\textit{m}$ full covariance matrix. In the former case, it is assumed that measurement uncertainty is uncorrelated. \n",
    "\n",
    "    err [m x m] or [m]   \n",
    "\n",
    "4. Model error coveriance matrix, $S_{b}$. This can be specificed as either an $\\textit{r}$ length vector of sigma squared measurement uncertainties or an $\\textit{r} x \\textit{r}$ full covariance matrix. In the former case, it is assumed that measurement uncertainty is uncorrelated. Note there are options below to omit consideration of model errors if these are not known.\n",
    "\n",
    "    err_me [m x m] or [m]   \n",
    "    \n",
    "5. A priori error coveriance matrix, $S_{a}$. This can be specificed as either an $\\textit{n}$ length vector of sigma squared measurement uncertainties or an $\\textit{n} x \\textit{n}$ full covariance matrix. In the former case, it is assumed that measurement uncertainty is uncorrelated. \n",
    "\n",
    "    ap [n x n] or [n]   \n",
    "    \n",
    "6. If calculating the detection probability: the value of the parameter in question\n",
    "\n",
    "    mu [scalar]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs\n",
    "\n",
    "\n",
    "### from rodgers()\n",
    "1. Error covariance matrix, $\\hat{S}$.\n",
    "\n",
    "    S_hat [n x n]\n",
    "    \n",
    "2. Shannon Information Content, $SIC$.\n",
    "\n",
    "    SIC [scalar]\n",
    "    \n",
    "3. Averaging kernel matrix, $A$. \n",
    "\n",
    "    AvgK [n x n]\n",
    "\n",
    "4. Degrees of Freedom for Signal, $DFS$. \n",
    "\n",
    "    DFS [scalar]  \n",
    "\n",
    "    \n",
    "### from detect_prob()\n",
    "1. Probability of detection, $P_d$. Note this requires inputs mu (parameter value in question) and sigma ($\\sqrt{\\hat{S}_{p,p}}$ where $p$ is the parameter index.)\n",
    "\n",
    "    Pd [scalar]\n",
    "    \n",
    "    Pd_pcnt_str [percentage as string]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from Amir:\n",
    "    Relative:\n",
    "σ_sys = np.array([0.01587401, 0.01244266, 0.00938955, 0.01092051, 0.00302288,\n",
    "                  0.00544271, 0.00999068, 0.01467843, 0.0080387, 0.00944394,\n",
    "                  0.0193447, 0.0224503, 0.02386379])\n",
    "\n",
    "Absolute:\n",
    "σ_sys = np.array([2.80453033e-03, 1.52152435e-03, 1.04028473e-03, 9.98138237e-04,\n",
    "                  1.12356970e-04, 2.68196657e-04, 4.69710954e-04, 4.32004600e-04,\n",
    "                  2.49862337e-04, 2.53730871e-04, 8.83851738e-05, 1.47447273e-04,\n",
    "                  1.57220696e-04])\n",
    "\n",
    "This is based on real modisa data using our OE algorithm, where we use the full spectrum to optimize things, which means that these values work better when you use all bands in MODIS. The systematic uncertainty dominates the random noise, so I feel comfortable ignoring the random component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the parameter error covariance matrix.\n",
    "\n",
    "#input Jacobian, K, [n x m], error covariance matrix Se, [m x m] and a priori matrix Sa, [n x n]\n",
    "#model_error and model_error_jacobian describe model uncertainty - that is, parameterized uncertainty \n",
    "#and its jacobian\n",
    "def rodgers(jac, err, ap, model_error={}, model_error_jacobian={}): \n",
    "    \n",
    "        #check if error covariance matrix is square, or just diagonal values. If latter make full matrix\n",
    "    if err.ndim == 1:\n",
    "        ln=np.shape(err)\n",
    "        err2d = np.zeros((ln[0], ln[0]))\n",
    "        np.fill_diagonal(err2d, err)\n",
    "        err=err2d\n",
    "\n",
    "        #check if a priori covariance matrix is square, or just diagonal values. If latter make full matrix\n",
    "    if ap.ndim == 1:\n",
    "        ln=np.shape(ap)\n",
    "        ap2d = np.zeros((ln[0], ln[0]))\n",
    "        np.fill_diagonal(ap2d, ap)\n",
    "        ap=ap2d        \n",
    "            \n",
    "        #section to verify compatable dimensions ------------------------------------------------------\n",
    "    sh_jac = np.shape(jac)\n",
    "    sh_err = np.shape(err)\n",
    "    sh_ap = np.shape(ap)\n",
    "    \n",
    "    n_dim = sh_jac[0]\n",
    "    m_dim = sh_jac[1]\n",
    "    \n",
    "    if not((sh_err[0] == sh_err[1]) and (sh_ap[0] == sh_ap[1])):\n",
    "        print('ERROR: error covariance matrix or a priori matrix are not square')\n",
    "        print('Error covariance matrix dimensions')\n",
    "        print(sh_err)\n",
    "        print('A priori matrix dimensions')\n",
    "        print(sh_ap)\n",
    "        return -1, -1, -1, -1\n",
    "    \n",
    "    if not(sh_jac[0] == sh_ap[0]):\n",
    "        print('ERROR: n dimensions inconsistent, should be Jacobian [n x m]; a priori [n x n]')\n",
    "        print('Jacobian matrix dimensions')\n",
    "        print(sh_jac)\n",
    "        print('A priori matrix dimensions')\n",
    "        print(sh_ap)\n",
    "        return -1, -1, -1, -1\n",
    "    \n",
    "    if not(sh_jac[1] == sh_err[0]):\n",
    "        print('ERROR: m dimensions inconsistent, should be Jacobian [n x m]; error covariance [m x m]')\n",
    "        print('Jacobian matrix dimensions')\n",
    "        print(sh_jac)\n",
    "        print('Error covariance matrix dimensions')\n",
    "        print(sh_err)\n",
    "        return -1, -1, -1, -1\n",
    "        \n",
    "    #section to generate model derived error -------------------------------------------------------\n",
    "    \n",
    "    if len(model_error) > 0:\n",
    "        me=model_error\n",
    "        jac_me=model_error_jacobian\n",
    "        \n",
    "        ln_me=np.shape(me)\n",
    "        errme_2d = np.zeros((ln_me[0], ln_me[0]))\n",
    "        np.fill_diagonal(errme_2d, me)\n",
    "        err_me=errme_2d\n",
    "    \n",
    "        jac_me_t=np.transpose(jac_me)      \n",
    "    \n",
    "        JacmetMeJacme = np.matmul(jac_me_t,np.matmul(err_me,jac_me))\n",
    "        err = err + JacmetMeJacme\n",
    "    \n",
    "        #perform inverse and matrix multiplication calculations ----------------------------------------\n",
    "    jac_t=np.transpose(jac) #transpose of Jacobian (KT)\n",
    "    \n",
    "    try: \n",
    "        err_i=np.linalg.inv(err) #inverse of error covariance matrix (Se-1)\n",
    "    except:\n",
    "        print(\"ERROR: problem inverting error covariance matrix\")\n",
    "        return -1, -1, -1, -1\n",
    "    \n",
    "    try: \n",
    "        ap_i=np.linalg.inv(ap) #inverse of a priori error covariance matrix\n",
    "    except:\n",
    "        print(\"ERROR: problem inverting a priori covariance matrix\")\n",
    "        return -1, -1, -1, -1\n",
    "\n",
    "    KtSK = np.matmul(jac,np.matmul(err_i,jac_t)) #calcuates KT Se-1 K\n",
    "\n",
    "    try: \n",
    "        S_hat = np.linalg.inv(KtSK+ap_i) #calculate the inverse of (above + Sa-1)\n",
    "    except:\n",
    "        print(\"ERROR: problem inverting retrieval error covariance matrix\")\n",
    "        return -1, -1, -1, -1\n",
    "    \n",
    "    #calculate retrieval error CORRELATION matrix  \n",
    "    Cor=np.zeros((n_dim,n_dim))\n",
    "    for xx in range(n_dim):\n",
    "        for yy in range(n_dim):\n",
    "            Cor[xx,yy]=(S_hat[xx,yy]*S_hat[xx,yy]) / (S_hat[xx,xx]*S_hat[yy,yy])\n",
    "#    print(np.round(Cor,3))\n",
    "    \n",
    "    SIC = 0.5*np.log(np.linalg.det(np.matmul((KtSK+ap_i),ap))) #calculate Shannon Information Content    \n",
    "    AvgK = np.matmul(S_hat,KtSK) #averaging kernel\n",
    "    DFS = np.trace(AvgK) #degrees of freedom for signal (DFS) which is trace of averaging kernel\n",
    "    \n",
    "    return S_hat, SIC, AvgK, DFS, Cor  #returns retrieval error covariance matrix, the Shannon Information Content,\n",
    "                        #the averaging kernel, the degrees of freedom for signal, error correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the probability of detection given the parameter value (mu) and uncertainty (sigma)\n",
    "#assumes PDF is gaussian normally distributed\n",
    "def detect_prob(mu, sigma, doprint=0): \n",
    "\n",
    "    Pd = 1-0.5*(1+erf((-1*mu)/(sigma*np.sqrt(2))))  #detection probability, modified from CDF function\n",
    "\n",
    "    Pd_pcnt_str=str(np.around(Pd*100,decimals=1))+'% positive probability' #string output version\n",
    "\n",
    "    if doprint > 0:\n",
    "        print(Pd_pcnt_str)\n",
    "\n",
    "    return Pd, Pd_pcnt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate detection probability metrics for a full range of fractional plastic coverage. \n",
    "#Also, return result at 95% or whatever is specified in fraction_threshold variable\n",
    "def detect_prob_all(plastic_uncertainty,plastic_fraction,fraction_threshold=0.95):    \n",
    "\n",
    "    #make array of values to assess (val) and dummy array to fill (det_prob)\n",
    "    inc=np.arange(0, 10000, 1)\n",
    "    val=inc/10000\n",
    "    det_prob=np.arange(0, 10000, 1) / 10000\n",
    "       \n",
    "    #interpolate plastic_uncertainty to assessment values\n",
    "    plastic_uncertainty_int = np.interp(val,plastic_fraction,plastic_uncertainty)    \n",
    "    \n",
    "    for x in inc:\n",
    "        Pd, Pd_pcnt_str = detect_prob(val[x], plastic_uncertainty_int[x], doprint=0)\n",
    "        det_prob[x] = Pd\n",
    "\n",
    "    #get plastic fraction for a fraction_threshold detection probability \n",
    "    fraction_meeting_threshold = np.interp(fraction_threshold,det_prob,val)\n",
    "    \n",
    "    return det_prob, fraction_meeting_threshold\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(S_hat, SIC, AvgK, DFS, jac, err, ap, me_err, numpts, params, me_params ):\n",
    "\n",
    "    S_hat_diag=np.diagonal(S_hat)\n",
    "    uncert=np.sqrt(S_hat_diag)\n",
    "\n",
    "    np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
    "    print('Error covariance matrix:')\n",
    "    print(S_hat)\n",
    "    print()\n",
    "\n",
    "    np.set_printoptions(formatter={'float': '{: 0.5f}'.format})\n",
    "    print('Averaging kernel matrix:')\n",
    "    print(AvgK)\n",
    "    print()\n",
    "    np.set_printoptions(formatter={'float': '{: 0.5f}'.format})\n",
    "    print('Model Parameters:       ', params)\n",
    "    print('Number of observations: ', numpts)\n",
    "    print('A priori uncertainty:   ', np.sqrt(ap))\n",
    "    print('Uncertainties:          ', uncert)\n",
    "    print('Shannon Information Content:      ', SIC)\n",
    "    print('Degrees of freedom for signal:    ', DFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section to read simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input/output and other specifics\n",
    "\n",
    "#file_in='simulations/Amir/plastics_toa_simulations_modisa_permutations_v5_non_biofouled.nc'\n",
    "\n",
    "rel_err = np.array([0.01587401, 0.01244266, 0.00938955, 0.01092051, 0.00302288,\n",
    "    0.00544271, 0.00999068, 0.01467843, 0.0080387, 0.00944394,\n",
    "    0.0193447, 0.0224503, 0.02386379])\n",
    "\n",
    "######################################################################################################\n",
    "#file_in='simulations/Amir/plastics_toa_simulations_modisa_permutations_v4.nc' #biofouled case\n",
    "#doBFunc = True #set to True to include biofouling model uncertainty as defined below \n",
    "#outname='data/SQOOP_Amir_BF' #Biofouled, with both model and measurement uncertainty\n",
    "\n",
    "######################################################################################################\n",
    "#file_in='simulations/Amir/plastics_toa_simulations_modisa_permutations_v4.nc' #biofouled case\n",
    "#doBFunc = True #set to True to include biofouling model uncertainty as defined below \n",
    "#rel_err = rel_err*2\n",
    "#outname='data/SQOOP_Amir_BF_x2unc' #Biofouled, with both model and doubled measurement uncertainty\n",
    "\n",
    "######################################################################################################\n",
    "#file_in='simulations/Amir/plastics_toa_simulations_modisa_permutations_v4.nc' #biofouled case\n",
    "#doBFunc = False #set to True to include biofouling model uncertainty as defined below \n",
    "#outname='data/SQOOP_Amir_BF_nomodunc' #Biofouled, with measurement uncertainty only (no modeling uncertainty)\n",
    "\n",
    "######################################################################################################\n",
    "file_in='simulations/Amir/plastics_toa_simulations_modisa_permutations_v5_non_biofouled.nc' #biofouled case\n",
    "doBFunc = True #set to True to include biofouling model uncertainty as defined below \n",
    "outname='data/SQOOP_Amir_NB' #non-Biofouled, with both model and measurement uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "including Biofouling model uncertainty\n"
     ]
    }
   ],
   "source": [
    "#section to set up systematic unc based on biofouling difference\n",
    "\n",
    "if doBFunc:\n",
    "    meas_BF,meas_NB = pd.read_pickle('data/SQOOP_Amir_biofoul.pkl')\n",
    "\n",
    "        #systemmatic uncertainty from biofouling is the difference between biofouled and\n",
    "        #non-biofouled, divided by 6 to represent a 1 sigma difference assuming 99% (3sigma)\n",
    "        #are represented by that difference between biofouled and non-biofouled\n",
    "    biofoul_err = (np.abs(meas_BF - meas_NB)) / 6.0\n",
    "    print('including Biofouling model uncertainty')\n",
    "else:\n",
    "    print('NOT including Biofouling model uncertainty')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read netcdf4 file with simulation\n",
    "f = netCDF4.Dataset(file_in)\n",
    "\n",
    "#read jacobian and data into jac and meas, respectively. Also get z (#cases,), m (measurent), n (param) lengths\n",
    "jac_all=np.asarray(f.variables['K_Jac'])\n",
    "meas=np.asarray(f.variables['rhot'])\n",
    "waveln=np.asarray(f.variables['wavelength'])\n",
    "g=jac_all.shape\n",
    "z_len=g[0]\n",
    "m_len=g[1]\n",
    "n_len=g[2]\n",
    "\n",
    "#read the simulation specific parameters into a dataframe\n",
    "df = pd.DataFrame({'Windspeed(m_s)': np.asarray(f.variables['Windspeed(m_s)']),\n",
    "                   'Humidity(%)': np.asarray(f.variables['Humidity(%)']),\n",
    "                   'FMF': np.asarray(f.variables['FMF']),\n",
    "                   'AOD(869)': np.asarray(f.variables['AOD(869)']),\n",
    "                   'chla(mg_m3)': np.asarray(f.variables['chla(mg_m3)']),\n",
    "                   'plastic_fraction': np.asarray(f.variables['plastic_fraction']), \n",
    "                   'solz': np.asarray(f.variables['solz']),     \n",
    "                   'relaz': np.asarray(f.variables['relaz']),  \n",
    "                   'senz': np.asarray(f.variables['senz']),  \n",
    "                  })\n",
    "\n",
    "df[\"plastic_uncertainty\"] = np.nan\n",
    "df[\"SIC\"] = np.nan\n",
    "df[\"plastic_avgK\"] = np.nan\n",
    "df[\"DFS\"] = np.nan\n",
    "df[\"Cor_5_0\"] = np.nan\n",
    "df[\"Cor_5_1\"] = np.nan\n",
    "df[\"Cor_5_2\"] = np.nan\n",
    "df[\"Cor_5_3\"] = np.nan\n",
    "df[\"Cor_5_4\"] = np.nan\n",
    "\n",
    "#close netcdf file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a priori covariance matrix\n",
    "\n",
    "#ap=(np.linspace(10.0,10.0,4))**2 #generate a priori error covariance matrix\n",
    "WS_range=df['Windspeed(m_s)'].max() - df['Windspeed(m_s)'].min()\n",
    "RH_range=df['Humidity(%)'].max() - df['Humidity(%)'].min()\n",
    "FMF_range=df['FMF'].max() - df['FMF'].min()\n",
    "AOD_range=df['AOD(869)'].max() - df['AOD(869)'].min()\n",
    "CHL_range=df['chla(mg_m3)'].max() - df['chla(mg_m3)'].min()\n",
    "PF_range=df['plastic_fraction'].max() - df['plastic_fraction'].min()\n",
    "\n",
    "\n",
    "ap=np.asarray([WS_range,RH_range,FMF_range,AOD_range,CHL_range,PF_range]) #generate a priori error covariance matrix\n",
    "ap=(ap/2)**2 #generate a priori error covariance matrix diagonals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 131220\n",
      "10000 of 131220\n",
      "20000 of 131220\n",
      "30000 of 131220\n",
      "40000 of 131220\n",
      "50000 of 131220\n",
      "60000 of 131220\n",
      "70000 of 131220\n",
      "80000 of 131220\n",
      "90000 of 131220\n",
      "100000 of 131220\n",
      "110000 of 131220\n",
      "120000 of 131220\n",
      "130000 of 131220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Windspeed(m_s)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>FMF</th>\n",
       "      <th>AOD(869)</th>\n",
       "      <th>chla(mg_m3)</th>\n",
       "      <th>plastic_fraction</th>\n",
       "      <th>solz</th>\n",
       "      <th>relaz</th>\n",
       "      <th>senz</th>\n",
       "      <th>plastic_uncertainty</th>\n",
       "      <th>SIC</th>\n",
       "      <th>plastic_avgK</th>\n",
       "      <th>DFS</th>\n",
       "      <th>Cor_5_0</th>\n",
       "      <th>Cor_5_1</th>\n",
       "      <th>Cor_5_2</th>\n",
       "      <th>Cor_5_3</th>\n",
       "      <th>Cor_5_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.037408</td>\n",
       "      <td>17.651534</td>\n",
       "      <td>0.994401</td>\n",
       "      <td>3.803067</td>\n",
       "      <td>0.957476</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.787578</td>\n",
       "      <td>0.161159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.021499</td>\n",
       "      <td>15.349779</td>\n",
       "      <td>0.998151</td>\n",
       "      <td>3.222553</td>\n",
       "      <td>0.952107</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>0.705399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.012907</td>\n",
       "      <td>14.811915</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>3.808128</td>\n",
       "      <td>0.153407</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.063871</td>\n",
       "      <td>0.996645</td>\n",
       "      <td>0.102897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>16.276321</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>3.946247</td>\n",
       "      <td>0.199036</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.992911</td>\n",
       "      <td>0.076764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>15.591507</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>3.681071</td>\n",
       "      <td>0.878175</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.998677</td>\n",
       "      <td>0.354362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131215</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.292222</td>\n",
       "      <td>17.217250</td>\n",
       "      <td>0.658357</td>\n",
       "      <td>3.364043</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.984358</td>\n",
       "      <td>0.404711</td>\n",
       "      <td>0.276835</td>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131216</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.046277</td>\n",
       "      <td>6.386301</td>\n",
       "      <td>0.991432</td>\n",
       "      <td>2.862484</td>\n",
       "      <td>0.026467</td>\n",
       "      <td>0.213448</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131217</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.023525</td>\n",
       "      <td>6.282039</td>\n",
       "      <td>0.997786</td>\n",
       "      <td>2.742566</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.371079</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.713541</td>\n",
       "      <td>0.005944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131218</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>6.319685</td>\n",
       "      <td>0.997944</td>\n",
       "      <td>2.774965</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.151251</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.723135</td>\n",
       "      <td>0.010173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131219</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.054338</td>\n",
       "      <td>6.086365</td>\n",
       "      <td>0.988187</td>\n",
       "      <td>2.586582</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.416075</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.941013</td>\n",
       "      <td>0.004282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131220 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Windspeed(m_s)  Humidity(%)   FMF  AOD(869)  chla(mg_m3)  \\\n",
       "0                  0.5         30.1  0.01      0.04         0.05   \n",
       "1                  0.5         30.1  0.01      0.04         0.05   \n",
       "2                  0.5         30.1  0.01      0.04         0.05   \n",
       "3                  0.5         30.1  0.01      0.04         0.05   \n",
       "4                  0.5         30.1  0.01      0.04         0.05   \n",
       "...                ...          ...   ...       ...          ...   \n",
       "131215            10.0         94.9  0.95      0.30         2.00   \n",
       "131216            10.0         94.9  0.95      0.30         2.00   \n",
       "131217            10.0         94.9  0.95      0.30         2.00   \n",
       "131218            10.0         94.9  0.95      0.30         2.00   \n",
       "131219            10.0         94.9  0.95      0.30         2.00   \n",
       "\n",
       "        plastic_fraction  solz  relaz  senz  plastic_uncertainty        SIC  \\\n",
       "0                 0.0001  15.0   40.0  15.0             0.037408  17.651534   \n",
       "1                 0.0001  15.0   40.0  30.0             0.021499  15.349779   \n",
       "2                 0.0001  15.0   40.0  60.0             0.012907  14.811915   \n",
       "3                 0.0001  15.0  110.0  15.0             0.010706  16.276321   \n",
       "4                 0.0001  15.0  110.0  30.0             0.014891  15.591507   \n",
       "...                  ...   ...    ...   ...                  ...        ...   \n",
       "131215            1.0000  60.0  110.0  30.0             0.292222  17.217250   \n",
       "131216            1.0000  60.0  110.0  60.0             0.046277   6.386301   \n",
       "131217            1.0000  60.0  170.0  15.0             0.023525   6.282039   \n",
       "131218            1.0000  60.0  170.0  30.0             0.022669   6.319685   \n",
       "131219            1.0000  60.0  170.0  60.0             0.054338   6.086365   \n",
       "\n",
       "        plastic_avgK       DFS   Cor_5_0   Cor_5_1   Cor_5_2   Cor_5_3  \\\n",
       "0           0.994401  3.803067  0.957476  0.000134  0.000043  0.787578   \n",
       "1           0.998151  3.222553  0.952107  0.000026  0.008617  0.999638   \n",
       "2           0.999334  3.808128  0.153407  0.000454  0.063871  0.996645   \n",
       "3           0.999541  3.946247  0.199036  0.003501  0.004500  0.992911   \n",
       "4           0.999113  3.681071  0.878175  0.004009  0.001104  0.998677   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "131215      0.658357  3.364043  0.001699  0.984358  0.404711  0.276835   \n",
       "131216      0.991432  2.862484  0.026467  0.213448  0.000659  0.680919   \n",
       "131217      0.997786  2.742566  0.002569  0.371079  0.000137  0.713541   \n",
       "131218      0.997944  2.774965  0.005709  0.151251  0.000718  0.723135   \n",
       "131219      0.988187  2.586582  0.007072  0.416075  0.003225  0.941013   \n",
       "\n",
       "         Cor_5_4  \n",
       "0       0.161159  \n",
       "1       0.705399  \n",
       "2       0.102897  \n",
       "3       0.076764  \n",
       "4       0.354362  \n",
       "...          ...  \n",
       "131215  0.001209  \n",
       "131216  0.005204  \n",
       "131217  0.005944  \n",
       "131218  0.010173  \n",
       "131219  0.004282  \n",
       "\n",
       "[131220 rows x 18 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make error covariance matrix and prepare jacobian\n",
    "for idx in range(0, z_len):\n",
    "#for idx in range(0, 6):\n",
    "\n",
    "    if (idx % 10000) == 0:\n",
    "        txt=str(idx)+' of '+str(z_len)\n",
    "        print(txt)\n",
    "    \n",
    "    if doBFunc:\n",
    "        sys_err = biofoul_err[idx,:]\n",
    "    else:\n",
    "        sys_err = np.zeros(13)    \n",
    "    \n",
    "    \n",
    "    err=((meas[idx]*rel_err) + sys_err)**2 #generate error covariance matrix diagonals (code also takes 2d input)        \n",
    "    \n",
    "    #prepare jacobian\n",
    "    this_jac=jac_all[idx]\n",
    "    jac=this_jac.transpose()\n",
    "\n",
    "    #check for NaN in jacobian\n",
    "    if np.isnan(this_jac).any(): \n",
    "        print('Nan found in index ',idx)\n",
    "    if np.isinf(this_jac).any(): \n",
    "        print('Inf found in index ',idx)\n",
    "    \n",
    "    #calculate rodgers stuff\n",
    "    S_hat, SIC, AvgK, DFS, Cor = rodgers(jac, err, ap)\n",
    "\n",
    "    df.loc[idx][\"plastic_uncertainty\"]=np.sqrt(S_hat[5,5]) \n",
    "    df.loc[idx][\"SIC\"]=SIC\n",
    "    df.loc[idx][\"plastic_avgK\"]=AvgK[5,5]\n",
    "    df.loc[idx][\"DFS\"]=DFS\n",
    "    df.loc[idx][\"Cor_5_0\"]=Cor[5,0] #these are correlation for plastic fraction with: wind speed\n",
    "    df.loc[idx][\"Cor_5_1\"]=Cor[5,1] #these are correlation for plastic fraction with: relative humidity\n",
    "    df.loc[idx][\"Cor_5_2\"]=Cor[5,2] #these are correlation for plastic fraction with: fine mode fraction\n",
    "    df.loc[idx][\"Cor_5_3\"]=Cor[5,3] #these are correlation for plastic fraction with: AOD\n",
    "    df.loc[idx][\"Cor_5_4\"]=Cor[5,4] #these are correlation for plastic fraction with: Chl-a           \n",
    "\n",
    "df_orig=df.copy()    \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 131220\n",
      "10000 of 131220\n",
      "20000 of 131220\n",
      "30000 of 131220\n",
      "40000 of 131220\n",
      "50000 of 131220\n",
      "60000 of 131220\n",
      "70000 of 131220\n",
      "80000 of 131220\n",
      "90000 of 131220\n",
      "100000 of 131220\n",
      "110000 of 131220\n",
      "120000 of 131220\n",
      "130000 of 131220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Windspeed(m_s)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>FMF</th>\n",
       "      <th>AOD(869)</th>\n",
       "      <th>chla(mg_m3)</th>\n",
       "      <th>plastic_threshold</th>\n",
       "      <th>solz</th>\n",
       "      <th>relaz</th>\n",
       "      <th>senz</th>\n",
       "      <th>plastic_unc_median</th>\n",
       "      <th>SIC_median</th>\n",
       "      <th>plastic_avgK_median</th>\n",
       "      <th>DFS_median</th>\n",
       "      <th>Cor_5_0_median</th>\n",
       "      <th>Cor_5_1_median</th>\n",
       "      <th>Cor_5_2_median</th>\n",
       "      <th>Cor_5_3_median</th>\n",
       "      <th>Cor_5_4_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.089223</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.039837</td>\n",
       "      <td>17.355668</td>\n",
       "      <td>0.993646</td>\n",
       "      <td>3.777812</td>\n",
       "      <td>0.954880</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.784545</td>\n",
       "      <td>0.155528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.039451</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.022180</td>\n",
       "      <td>14.579890</td>\n",
       "      <td>0.998032</td>\n",
       "      <td>3.111027</td>\n",
       "      <td>0.930775</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.690657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.046912</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>14.007116</td>\n",
       "      <td>0.999087</td>\n",
       "      <td>3.716834</td>\n",
       "      <td>0.133792</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.035695</td>\n",
       "      <td>0.996790</td>\n",
       "      <td>0.177032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.035650</td>\n",
       "      <td>15.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.014433</td>\n",
       "      <td>15.429483</td>\n",
       "      <td>0.999154</td>\n",
       "      <td>3.895116</td>\n",
       "      <td>0.213624</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.993571</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.034466</td>\n",
       "      <td>15.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.017816</td>\n",
       "      <td>14.782096</td>\n",
       "      <td>0.998725</td>\n",
       "      <td>3.504769</td>\n",
       "      <td>0.872795</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.357345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13116</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.014921</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.011916</td>\n",
       "      <td>10.696753</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>3.263153</td>\n",
       "      <td>0.054997</td>\n",
       "      <td>0.171041</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.086587</td>\n",
       "      <td>0.006119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13117</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>17.621763</td>\n",
       "      <td>0.999330</td>\n",
       "      <td>3.404185</td>\n",
       "      <td>0.023241</td>\n",
       "      <td>0.315354</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.183567</td>\n",
       "      <td>0.008409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13118</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>10.091490</td>\n",
       "      <td>0.997603</td>\n",
       "      <td>3.204446</td>\n",
       "      <td>0.055207</td>\n",
       "      <td>0.298791</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.090963</td>\n",
       "      <td>0.009895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13119</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>60.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>10.715292</td>\n",
       "      <td>0.999476</td>\n",
       "      <td>3.321224</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>0.472429</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.305049</td>\n",
       "      <td>0.004365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13120</th>\n",
       "      <td>10.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.034250</td>\n",
       "      <td>60.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.018645</td>\n",
       "      <td>10.508628</td>\n",
       "      <td>0.998608</td>\n",
       "      <td>3.296352</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.777331</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.546886</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13121 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Windspeed(m_s)  Humidity(%)   FMF  AOD(869)  chla(mg_m3)  \\\n",
       "0                 0.5         30.1  0.01      0.04         0.05   \n",
       "1                 0.5         30.1  0.01      0.04         0.05   \n",
       "2                 0.5         30.1  0.01      0.04         0.05   \n",
       "3                 0.5         30.1  0.01      0.04         0.05   \n",
       "4                 0.5         30.1  0.01      0.04         0.05   \n",
       "...               ...          ...   ...       ...          ...   \n",
       "13116            10.0         94.9  0.95      0.30         2.00   \n",
       "13117            10.0         94.9  0.95      0.30         2.00   \n",
       "13118            10.0         94.9  0.95      0.30         2.00   \n",
       "13119            10.0         94.9  0.95      0.30         2.00   \n",
       "13120            10.0         94.9  0.95      0.30         2.00   \n",
       "\n",
       "       plastic_threshold  solz  relaz  senz  plastic_unc_median  SIC_median  \\\n",
       "0               0.089223  15.0   40.0  15.0            0.039837   17.355668   \n",
       "1               0.039451  15.0   40.0  30.0            0.022180   14.579890   \n",
       "2               0.046912  15.0   40.0  60.0            0.015110   14.007116   \n",
       "3               0.035650  15.0  110.0  15.0            0.014433   15.429483   \n",
       "4               0.034466  15.0  110.0  30.0            0.017816   14.782096   \n",
       "...                  ...   ...    ...   ...                 ...         ...   \n",
       "13116           0.014921  60.0  110.0  15.0            0.011916   10.696753   \n",
       "13117           0.014592  60.0  110.0  30.0            0.012943   17.621763   \n",
       "13118           0.068010  60.0  110.0  60.0            0.024123   10.091490   \n",
       "13119           0.018722  60.0  170.0  15.0            0.011439   10.715292   \n",
       "13120           0.034250  60.0  170.0  30.0            0.018645   10.508628   \n",
       "\n",
       "       plastic_avgK_median  DFS_median  Cor_5_0_median  Cor_5_1_median  \\\n",
       "0                 0.993646    3.777812        0.954880        0.000139   \n",
       "1                 0.998032    3.111027        0.930775        0.000024   \n",
       "2                 0.999087    3.716834        0.133792        0.000374   \n",
       "3                 0.999154    3.895116        0.213624        0.001815   \n",
       "4                 0.998725    3.504769        0.872795        0.001255   \n",
       "...                    ...         ...             ...             ...   \n",
       "13116             0.999432    3.263153        0.054997        0.171041   \n",
       "13117             0.999330    3.404185        0.023241        0.315354   \n",
       "13118             0.997603    3.204446        0.055207        0.298791   \n",
       "13119             0.999476    3.321224        0.023740        0.472429   \n",
       "13120             0.998608    3.296352        0.000665        0.777331   \n",
       "\n",
       "       Cor_5_2_median  Cor_5_3_median  Cor_5_4_median  \n",
       "0            0.000043        0.784545        0.155528  \n",
       "1            0.006143        0.999400        0.690657  \n",
       "2            0.035695        0.996790        0.177032  \n",
       "3            0.001816        0.993571        0.096727  \n",
       "4            0.000781        0.998149        0.357345  \n",
       "...               ...             ...             ...  \n",
       "13116        0.002241        0.086587        0.006119  \n",
       "13117        0.007821        0.183567        0.008409  \n",
       "13118        0.000603        0.090963        0.009895  \n",
       "13119        0.000407        0.305049        0.004365  \n",
       "13120        0.000051        0.546886        0.005185  \n",
       "\n",
       "[13121 rows x 18 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterate through each set of conditions that have all the same parameter value except for plastic fraction. \n",
    "#create a new dataframe, and save one row for each set, with median values for plastic_uncertainty, SIC, plastic_avgK and DFS\n",
    "#also, assess detection probability and save the plastic fraction value for 90% confident probability.\n",
    "\n",
    "df.sort_values(by=['Windspeed(m_s)','Humidity(%)','FMF','AOD(869)','chla(mg_m3)','solz','relaz','senz'], inplace=True)\n",
    "\n",
    "df.rename(columns={'plastic_fraction': 'plastic_threshold', 'plastic_uncertainty': 'plastic_unc_median', 'SIC': 'SIC_median', \\\n",
    "                   'plastic_avgK':'plastic_avgK_median', 'DFS': 'DFS_median', 'Cor_5_0': 'Cor_5_0_median', \\\n",
    "                   'Cor_5_1': 'Cor_5_1_median','Cor_5_2': 'Cor_5_2_median','Cor_5_3': 'Cor_5_3_median', \\\n",
    "                   'Cor_5_4': 'Cor_5_4_median'}, inplace=True)\n",
    "\n",
    "fdf = df.copy()\n",
    "fdfe = fdf[0:0]\n",
    "\n",
    "for idx in range(0, z_len-10, 10):\n",
    "    if (idx % 10000) == 0:\n",
    "        txt=str(idx)+' of '+str(z_len)\n",
    "        print(txt)\n",
    "    \n",
    "    #get start and end points for this iteration\n",
    "    st=idx\n",
    "    ed=idx+10\n",
    "\n",
    "    this=df.iloc[st:ed]\n",
    "\n",
    "    this_plastic_fraction = np.asarray(df.iloc[st:ed]['plastic_threshold'])   \n",
    "    this_plastic_uncertainty = np.asarray(df.iloc[st:ed]['plastic_unc_median'])   \n",
    "\n",
    "    this_detect_prob, fraction_meeting_threshold = \\\n",
    "        detect_prob_all(this_plastic_uncertainty,this_plastic_fraction,fraction_threshold=0.95)\n",
    "\n",
    "    fdfe = fdfe.append(df.iloc[st], ignore_index = True)\n",
    "        \n",
    "    fdfe.loc[fdfe.index[-1], 'plastic_threshold']= fraction_meeting_threshold\n",
    "    \n",
    "    #section to update field with median values for set\n",
    "    fdfe.loc[fdfe.index[-1], 'plastic_unc_median']= np.median(this_plastic_uncertainty)\n",
    "    fdfe.loc[fdfe.index[-1], 'SIC_median']= np.median(np.asarray(df.iloc[st:ed]['SIC_median']))\n",
    "    fdfe.loc[fdfe.index[-1], 'plastic_avgK_median']= np.median(np.asarray(df.iloc[st:ed]['plastic_avgK_median']))\n",
    "    fdfe.loc[fdfe.index[-1], 'DFS_median']= np.median(np.asarray(df.iloc[st:ed]['DFS_median']))\n",
    "    fdfe.loc[fdfe.index[-1], 'Cor_5_0_median']= np.median(np.asarray(df.iloc[st:ed]['Cor_5_0_median']))\n",
    "    fdfe.loc[fdfe.index[-1], 'Cor_5_1_median']= np.median(np.asarray(df.iloc[st:ed]['Cor_5_1_median']))\n",
    "    fdfe.loc[fdfe.index[-1], 'Cor_5_2_median']= np.median(np.asarray(df.iloc[st:ed]['Cor_5_2_median']))\n",
    "    fdfe.loc[fdfe.index[-1], 'Cor_5_3_median']= np.median(np.asarray(df.iloc[st:ed]['Cor_5_3_median']))\n",
    "    fdfe.loc[fdfe.index[-1], 'Cor_5_4_median']= np.median(np.asarray(df.iloc[st:ed]['Cor_5_4_median']))\n",
    "    \n",
    "#change names in original df back\n",
    "df.rename(columns={'plastic_threshold':'plastic_fraction', 'plastic_unc_median':'plastic_uncertainty', 'SIC_median':'SIC', \\\n",
    "                   'plastic_avgK_median':'plastic_avgK', 'DFS_median':'DFS', 'Cor_5_0_median':'Cor_5_0', \\\n",
    "                   'Cor_5_1_median':'Cor_5_1', 'Cor_5_2_median':'Cor_5_2', 'Cor_5_3_median':'Cor_5_3', \\\n",
    "                   'Cor_5_4_median':'Cor_5_4'}, inplace=True)\n",
    "\n",
    "fdfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes to pickle files\n",
    "\n",
    "df_name=outname+'_df.pkl'\n",
    "fdfe_name=outname+'_fdfe.pkl'\n",
    "vars_name=outname+'_vars.pkl'\n",
    "\n",
    "df.to_pickle(df_name)\n",
    "fdfe.to_pickle(fdfe_name) \n",
    "\n",
    "f = open(vars_name, 'wb')\n",
    "pickle.dump([waveln,meas,rel_err,sys_err,jac_all],f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
